"""Main Shesha class - the public API."""

import atexit
import re
import weakref
from pathlib import Path
from typing import TYPE_CHECKING, Literal

import docker
from docker.errors import DockerException

from shesha.analysis import AnalysisGenerator
from shesha.config import SheshaConfig
from shesha.exceptions import RepoIngestError
from shesha.models import ParsedDocument, ProjectInfo, RepoProjectResult
from shesha.parser import create_default_registry
from shesha.project import Project
from shesha.repo.ingester import RepoIngester
from shesha.rlm.engine import RLMEngine
from shesha.sandbox.pool import ContainerPool
from shesha.storage.filesystem import FilesystemStorage

if TYPE_CHECKING:
    from shesha.models import RepoAnalysis
    from shesha.parser.base import DocumentParser


class Shesha:
    """Main entry point for Shesha - Recursive Language Models."""

    def __init__(
        self,
        model: str | None = None,
        storage_path: str | Path | None = None,
        api_key: str | None = None,
        pool_size: int | None = None,
        config: SheshaConfig | None = None,
    ) -> None:
        """Initialize Shesha."""
        # Verify Docker is available before proceeding
        self._check_docker_available()

        # Use provided config or create from args
        if config is None:
            config = SheshaConfig()
        if model is not None:
            config.model = model
        if storage_path is not None:
            config.storage_path = str(storage_path)
        if api_key is not None:
            config.api_key = api_key
        if pool_size is not None:
            config.pool_size = pool_size

        self._config = config

        # Initialize components
        self._storage = FilesystemStorage(
            config.storage_path,
            keep_raw_files=config.keep_raw_files,
        )
        self._parser_registry = create_default_registry()
        self._pool = ContainerPool(
            size=config.pool_size,
            image=config.sandbox_image,
            memory_limit=f"{config.container_memory_mb}m",
        )

        # Create RLM engine
        self._rlm_engine = RLMEngine(
            model=config.model,
            api_key=config.api_key,
            max_iterations=config.max_iterations,
            max_output_chars=config.max_output_chars,
            execution_timeout=config.execution_timeout_sec,
        )

        # Initialize repo ingester
        self._repo_ingester = RepoIngester(storage_path=config.storage_path)

        # Track if stopped to avoid double-cleanup
        self._stopped = False

        # Register cleanup on exit using weak reference
        weak_self = weakref.ref(self)

        def _cleanup() -> None:
            obj = weak_self()
            if obj is not None:
                obj.stop()

        atexit.register(_cleanup)

    @staticmethod
    def _check_docker_available() -> None:
        """Verify Docker daemon is running. Raises RuntimeError if not."""
        try:
            client = docker.from_env()
            client.close()
        except DockerException as e:
            error_str = str(e)
            if "Connection refused" in error_str:
                raise RuntimeError(
                    "Docker is not running. Please start Docker Desktop and try again."
                ) from e
            if "No such file or directory" in error_str:
                raise RuntimeError(
                    "No Docker-compatible socket found. "
                    "If you're using Podman, set DOCKER_HOST to Podman's socket:\n"
                    '  export DOCKER_HOST="unix://$(podman machine inspect '
                    "--format '{{.ConnectionInfo.PodmanSocket.Path}}')\""
                ) from e
            raise

    def create_project(self, project_id: str) -> Project:
        """Create a new project."""
        self._storage.create_project(project_id)
        return Project(
            project_id=project_id,
            storage=self._storage,
            parser_registry=self._parser_registry,
            rlm_engine=self._rlm_engine,
        )

    def get_project(self, project_id: str) -> Project:
        """Get an existing project."""
        if not self._storage.project_exists(project_id):
            raise ValueError(f"Project '{project_id}' does not exist")
        return Project(
            project_id=project_id,
            storage=self._storage,
            parser_registry=self._parser_registry,
            rlm_engine=self._rlm_engine,
        )

    def list_projects(self) -> list[str]:
        """List all projects."""
        return self._storage.list_projects()

    def delete_project(self, project_id: str, *, cleanup_repo: bool = True) -> None:
        """Delete a project and optionally its cloned repository.

        Args:
            project_id: Project to delete.
            cleanup_repo: If True (default), also removes cloned repo data
                for remote repositories. Has no effect for projects
                created from local paths.
        """
        if cleanup_repo:
            source_url = self._repo_ingester.get_source_url(project_id)
            if source_url and not self._repo_ingester.is_local_path(source_url):
                self._repo_ingester.delete_repo(project_id)

        self._storage.delete_project(project_id)

    def get_project_info(self, project_id: str) -> ProjectInfo:
        """Get metadata about a project.

        Args:
            project_id: ID of the project.

        Returns:
            ProjectInfo with source URL, whether it's local, source existence,
            and analysis status.

        Raises:
            ValueError: If project doesn't exist.
        """
        if not self._storage.project_exists(project_id):
            raise ValueError(f"Project '{project_id}' does not exist")

        source_url = self._repo_ingester.get_source_url(project_id)
        analysis_status = self.get_analysis_status(project_id)

        if source_url is None:
            return ProjectInfo(
                project_id=project_id,
                source_url=None,
                is_local=False,
                source_exists=True,
                analysis_status=analysis_status,
            )

        is_local = self._repo_ingester.is_local_path(source_url)

        if is_local:
            source_exists = Path(source_url).expanduser().exists()
        else:
            source_exists = True  # Remote repos always "exist"

        return ProjectInfo(
            project_id=project_id,
            source_url=source_url,
            is_local=is_local,
            source_exists=source_exists,
            analysis_status=analysis_status,
        )

    def get_analysis_status(self, project_id: str) -> Literal["current", "stale", "missing"]:
        """Check the status of a project's codebase analysis.

        Args:
            project_id: ID of the project.

        Returns:
            "current" if analysis exists and matches current HEAD SHA,
            "stale" if analysis exists but HEAD SHA has changed,
            "missing" if no analysis exists.

        Raises:
            ValueError: If project doesn't exist.
        """
        if not self._storage.project_exists(project_id):
            raise ValueError(f"Project '{project_id}' does not exist")

        analysis = self._storage.load_analysis(project_id)
        if analysis is None:
            return "missing"

        current_sha = self._repo_ingester.get_saved_sha(project_id)
        if current_sha is None:
            return "current"

        if analysis.head_sha == current_sha:
            return "current"

        return "stale"

    def get_analysis(self, project_id: str) -> "RepoAnalysis | None":
        """Get the codebase analysis for a project.

        Args:
            project_id: ID of the project.

        Returns:
            RepoAnalysis if it exists, None otherwise.

        Raises:
            ValueError: If project doesn't exist.
        """
        if not self._storage.project_exists(project_id):
            raise ValueError(f"Project '{project_id}' does not exist")
        return self._storage.load_analysis(project_id)

    def get_project_sha(self, project_id: str) -> str | None:
        """Get the saved HEAD SHA for a project.

        Args:
            project_id: ID of the project.

        Returns:
            The SHA string, or None if not available.
        """
        return self._repo_ingester.get_saved_sha(project_id)

    def generate_analysis(self, project_id: str) -> "RepoAnalysis":
        """Generate and store a codebase analysis for a project.

        Args:
            project_id: ID of the project to analyze.

        Returns:
            The generated RepoAnalysis.

        Raises:
            ValueError: If project doesn't exist.
        """
        if not self._storage.project_exists(project_id):
            raise ValueError(f"Project '{project_id}' does not exist")

        generator = AnalysisGenerator(self)
        analysis = generator.generate(project_id)
        self._storage.store_analysis(project_id, analysis)
        return analysis

    def check_repo_for_updates(self, project_id: str) -> RepoProjectResult:
        """Check if a cloned repository has updates available.

        This retrieves the stored repository URL and checks if the remote
        has newer commits than the locally cached version.

        Args:
            project_id: ID of an existing project created from a repository.

        Returns:
            RepoProjectResult with status 'unchanged' or 'updates_available'.

        Raises:
            ValueError: If project doesn't exist or has no stored repo URL.
        """
        if not self._storage.project_exists(project_id):
            raise ValueError(f"Project '{project_id}' does not exist")

        url = self._repo_ingester.get_source_url(project_id)
        if not url:
            raise ValueError(
                f"No repository URL found for project '{project_id}'. "
                "This project may not have been created from a repository."
            )

        token = self._repo_ingester.resolve_token(url, None)
        return self._handle_existing_project(url, project_id, token, None)

    def register_parser(self, parser: "DocumentParser") -> None:
        """Register a custom document parser."""
        self._parser_registry.register(parser)

    def start(self) -> None:
        """Start the container pool."""
        self._stopped = False
        self._pool.start()

    def stop(self) -> None:
        """Stop the container pool."""
        if self._stopped:
            return
        self._stopped = True
        self._pool.stop()

    def __enter__(self) -> "Shesha":
        """Context manager entry."""
        self.start()
        return self

    def __exit__(self, *args: object) -> None:
        """Context manager exit."""
        self.stop()

    def create_project_from_repo(
        self,
        url: str,
        name: str | None = None,
        token: str | None = None,
        path: str | None = None,
    ) -> RepoProjectResult:
        """Create a project from a git repository.

        Args:
            url: Git URL (HTTPS, SSH) or local path.
            name: Project name (defaults to repo name).
            token: Auth token (defaults to env var based on host).
            path: Optional subdirectory to ingest.

        Returns:
            RepoProjectResult with project and status.
        """
        if name is None:
            name = self._extract_repo_name(url)

        resolved_token = self._repo_ingester.resolve_token(url, token)

        if self._storage.project_exists(name):
            return self._handle_existing_project(url, name, resolved_token, path)

        return self._create_new_project_from_repo(url, name, resolved_token, path)

    def _extract_repo_name(self, url: str) -> str:
        """Extract repository name from URL."""
        cleaned = url.rstrip("/")
        if self._repo_ingester.is_local_path(url):
            path = Path(cleaned).expanduser().resolve()
            return f"{path.parent.name}-{path.name}"
        match = re.search(r"[/:]([^/]+/[^/]+?)(?:\.git)?$", cleaned)
        if match:
            return match.group(1).replace("/", "-")
        return "unnamed-repo"

    def _handle_existing_project(
        self,
        url: str,
        name: str,
        token: str | None,
        path: str | None,
    ) -> RepoProjectResult:
        """Handle create_project_from_repo for existing project."""
        saved_sha = self._repo_ingester.get_saved_sha(name)
        if self._repo_ingester.is_local_path(url):
            current_sha = self._repo_ingester.get_sha_from_path(Path(url).expanduser())
        else:
            current_sha = self._repo_ingester.get_remote_sha(url, token)

        project = self.get_project(name)

        if saved_sha == current_sha:
            return RepoProjectResult(
                project=project,
                status="unchanged",
                files_ingested=len(self._storage.list_documents(name)),
            )

        def apply_updates() -> RepoProjectResult:
            if not self._repo_ingester.is_local_path(url):
                self._repo_ingester.pull(name)
            return self._ingest_repo(url, name, token, path, is_update=True)

        return RepoProjectResult(
            project=project,
            status="updates_available",
            files_ingested=len(self._storage.list_documents(name)),
            _apply_updates_fn=apply_updates,
        )

    def _create_new_project_from_repo(
        self,
        url: str,
        name: str,
        token: str | None,
        path: str | None,
    ) -> RepoProjectResult:
        """Create a new project from repo."""
        if self._repo_ingester.is_local_path(url):
            local_path = Path(url).expanduser()
            if not self._repo_ingester.is_git_repo(local_path):
                raise RepoIngestError(url, RuntimeError(f"'{url}' is not a git repository"))
        else:
            self._repo_ingester.clone(url, name, token)
        return self._ingest_repo(url, name, token, path, is_update=False)

    def _ingest_repo(
        self,
        url: str,
        name: str,
        token: str | None,
        path: str | None,
        *,
        is_update: bool,
    ) -> RepoProjectResult:
        """Ingest files from repository into project."""
        if not is_update:
            self._storage.create_project(name)

        is_local = self._repo_ingester.is_local_path(url)
        if is_local:
            repo_path = Path(url).expanduser()
        else:
            repo_path = self._repo_ingester.repos_dir / name

        files = self._repo_ingester.list_files_from_path(repo_path, subdir=path)
        files_ingested = 0
        files_skipped = 0
        warnings: list[str] = []

        for file_path in files:
            full_path = repo_path / file_path
            try:
                parser = self._parser_registry.find_parser(full_path)
                if parser is None:
                    files_skipped += 1
                    continue

                doc = parser.parse(full_path, include_line_numbers=True, file_path=file_path)
                doc = ParsedDocument(
                    name=file_path,
                    content=doc.content,
                    format=doc.format,
                    metadata=doc.metadata,
                    char_count=doc.char_count,
                    parse_warnings=doc.parse_warnings,
                )
                self._storage.store_document(name, doc)
                files_ingested += 1
            except Exception as e:
                files_skipped += 1
                warnings.append(f"Failed to parse {file_path}: {e}")

        sha = self._repo_ingester.get_sha_from_path(repo_path)
        if sha:
            self._repo_ingester.save_sha(name, sha)

        # Save source URL for later retrieval
        self._repo_ingester.save_source_url(name, url)

        project = self.get_project(name)
        return RepoProjectResult(
            project=project,
            status="created",
            files_ingested=files_ingested,
            files_skipped=files_skipped,
            warnings=warnings,
        )
