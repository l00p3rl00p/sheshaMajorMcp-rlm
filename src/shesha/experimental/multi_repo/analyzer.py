"""Multi-repo PRD analyzer using federated queries."""

import json
import re
from collections.abc import Callable
from pathlib import Path
from typing import TYPE_CHECKING, Any

from shesha.experimental.multi_repo.models import (
    AlignmentReport,
    HLDDraft,
    ImpactReport,
    RepoSummary,
)

if TYPE_CHECKING:
    from shesha import Shesha


class MultiRepoAnalyzer:
    """Federated PRD analysis across multiple repositories.

    Coordinates analysis of how a PRD impacts multiple codebases,
    running queries against individual projects and synthesizing
    results into a draft HLD.
    """

    def __init__(
        self,
        shesha: "Shesha",
        max_discovery_rounds: int = 2,
        max_revision_rounds: int = 2,
        phase_timeout_seconds: int = 300,
        total_timeout_seconds: int = 1800,
    ) -> None:
        """Initialize the analyzer.

        Args:
            shesha: Shesha instance for project management.
            max_discovery_rounds: Max rounds of discovering new repos (default 2).
            max_revision_rounds: Max rounds of HLD revision (default 2).
            phase_timeout_seconds: Timeout per phase query (default 5 min).
            total_timeout_seconds: Total analysis timeout (default 30 min).
        """
        self._shesha = shesha
        self._max_discovery_rounds = max_discovery_rounds
        self._max_revision_rounds = max_revision_rounds
        self._phase_timeout_seconds = phase_timeout_seconds
        self._total_timeout_seconds = total_timeout_seconds

        self._repos: list[str] = []
        self._summaries: dict[str, RepoSummary] = {}
        self._impacts: dict[str, ImpactReport] = {}
        self._failed_repos: dict[str, str] = {}

    @property
    def repos(self) -> list[str]:
        """List of project_ids currently in the analysis."""
        return self._repos

    @property
    def summaries(self) -> dict[str, RepoSummary]:
        """Recon summaries by project_id (populated after Phase 1)."""
        return self._summaries

    @property
    def impacts(self) -> dict[str, ImpactReport]:
        """Impact reports by project_id (populated after Phase 2)."""
        return self._impacts

    @property
    def failed_repos(self) -> dict[str, str]:
        """Repos that failed to add, with error messages."""
        return self._failed_repos

    def add_repo(self, url_or_path: str) -> str | None:
        """Add a repo to the analysis.

        If the repo was previously indexed, reuses it (with update check).
        If updates are available, they are automatically applied.

        Args:
            url_or_path: Git repository URL or local filesystem path.

        Returns:
            The project_id for the added repository, or None if failed.
        """
        try:
            result = self._shesha.create_project_from_repo(url_or_path)

            # Apply updates if available
            if result.status == "updates_available":
                result = result.apply_updates()

            project_id = result.project.project_id

            # Avoid duplicates
            if project_id not in self._repos:
                self._repos.append(project_id)

            return project_id
        except Exception as e:
            self._failed_repos[url_or_path] = str(e)
            return None

    def _load_prompt(self, name: str) -> str:
        """Load a prompt template from the prompts directory."""
        prompts_dir = Path(__file__).parent / "prompts"
        return (prompts_dir / f"{name}.md").read_text()

    def _extract_json(self, text: str) -> dict[str, Any] | None:
        """Extract JSON object from text that may contain markdown."""
        # Try to find JSON in code blocks first (greedy match for nested braces)
        json_match = re.search(r"```(?:json)?\s*(\{.*\})\s*```", text, re.DOTALL)
        if json_match:
            try:
                result: dict[str, Any] = json.loads(json_match.group(1))
                return result
            except json.JSONDecodeError:
                pass

        # Try to find raw JSON by looking for balanced braces
        # Find first { and try parsing from there
        start_idx = text.find("{")
        if start_idx != -1:
            # Try progressively longer substrings until we find valid JSON
            for end_idx in range(len(text) - 1, start_idx, -1):
                if text[end_idx] == "}":
                    candidate = text[start_idx : end_idx + 1]
                    try:
                        result = json.loads(candidate)
                        return result
                    except json.JSONDecodeError:
                        continue

        return None

    def _run_recon(self, project_id: str) -> RepoSummary:
        """Run Phase 1 recon on a single project.

        Args:
            project_id: The project to analyze.

        Returns:
            RepoSummary with extracted structure.
        """
        project = self._shesha.get_project(project_id)
        prompt = self._load_prompt("recon")

        result = project.query(prompt)
        answer = result.answer

        # Try to extract structured data
        data = self._extract_json(answer)

        if data:
            return RepoSummary(
                project_id=project_id,
                apis=data.get("apis", []),
                models=data.get("models", []),
                entry_points=data.get("entry_points", []),
                dependencies=data.get("dependencies", []),
                raw_summary=answer,
            )

        # Fallback: return raw answer with empty lists
        return RepoSummary(
            project_id=project_id,
            raw_summary=answer,
        )

    def _run_impact(
        self,
        project_id: str,
        prd: str,
        summary: RepoSummary,
    ) -> ImpactReport:
        """Run Phase 2 impact analysis on a single project."""
        project = self._shesha.get_project(project_id)
        prompt_template = self._load_prompt("impact")

        prompt = prompt_template.replace("{prd}", prd)
        prompt = prompt.replace("{repo_summary}", summary.raw_summary)

        result = project.query(prompt)
        answer = result.answer

        data = self._extract_json(answer)

        if data:
            return ImpactReport(
                project_id=project_id,
                affected=data.get("affected", False),
                changes=data.get("changes", []),
                new_interfaces=data.get("new_interfaces", []),
                modified_interfaces=data.get("modified_interfaces", []),
                discovered_dependencies=data.get("discovered_dependencies", []),
                raw_analysis=answer,
            )

        return ImpactReport(
            project_id=project_id,
            affected=True,
            raw_analysis=answer,
        )

    def _run_synthesize(
        self,
        prd: str,
        impacts: dict[str, ImpactReport],
    ) -> HLDDraft:
        """Run Phase 3 HLD synthesis."""
        project = self._shesha.get_project(self._repos[0])
        prompt_template = self._load_prompt("synthesize")

        impact_text = "\n\n".join(
            f"### {pid}\n{report.raw_analysis}" for pid, report in impacts.items()
        )

        prompt = prompt_template.replace("{prd}", prd)
        prompt = prompt.replace("{impact_reports}", impact_text)

        result = project.query(prompt)
        answer = result.answer

        data = self._extract_json(answer)

        if data:
            return HLDDraft(
                component_changes=data.get("component_changes", {}),
                data_flow=data.get("data_flow", ""),
                interface_contracts=data.get("interface_contracts", []),
                implementation_sequence=data.get("implementation_sequence", []),
                open_questions=data.get("open_questions", []),
                raw_hld=answer,
            )

        return HLDDraft(raw_hld=answer)

    def _run_align(
        self,
        prd: str,
        hld: HLDDraft,
    ) -> AlignmentReport:
        """Run Phase 4 alignment verification."""
        project = self._shesha.get_project(self._repos[0])
        prompt_template = self._load_prompt("align")

        prompt = prompt_template.replace("{prd}", prd)
        prompt = prompt.replace("{hld}", hld.raw_hld)

        result = project.query(prompt)
        answer = result.answer

        data = self._extract_json(answer)

        if data:
            return AlignmentReport(
                covered=data.get("covered", []),
                gaps=data.get("gaps", []),
                scope_creep=data.get("scope_creep", []),
                alignment_score=float(data.get("alignment_score", 0.0)),
                recommendation=data.get("recommendation", "revise"),
                raw_analysis=answer,
            )

        return AlignmentReport(
            alignment_score=0.0,
            recommendation="revise",
            raw_analysis=answer,
        )

    def analyze(
        self,
        prd: str,
        on_discovery: Callable[[str], bool] | None = None,
        on_alignment_issue: Callable[[AlignmentReport], str] | None = None,
        on_progress: Callable[[str, str], None] | None = None,
    ) -> tuple[HLDDraft, AlignmentReport]:
        """Run the four-phase analysis.

        Args:
            prd: The PRD text (pasted inline).
            on_discovery: Called when new repo discovered.
                Receives repo hint, returns True to add it.
                If None, discoveries are ignored.
            on_alignment_issue: Called if alignment finds problems.
                Receives report, returns "revise" | "accept" | "abort".
                If None, accepts as-is.
            on_progress: Called with (phase, message) updates.

        Returns:
            Tuple of (final HLD, alignment report).

        Raises:
            ValueError: If no repos have been added.
        """
        if not self._repos:
            raise ValueError("No repos added. Call add_repo() first.")

        # Phase 1: Recon
        if on_progress:
            on_progress("recon", f"Starting recon on {len(self._repos)} repos")

        for project_id in self._repos:
            if on_progress:
                on_progress("recon", f"Analyzing {project_id}")
            self._summaries[project_id] = self._run_recon(project_id)

        # Phase 2: Impact
        if on_progress:
            on_progress("impact", "Starting impact analysis")

        discovered: set[str] = set()
        discovery_round = 0

        while discovery_round < self._max_discovery_rounds:
            for project_id in self._repos:
                if project_id in self._impacts:
                    continue  # Already analyzed

                if on_progress:
                    on_progress("impact", f"Analyzing {project_id}")

                summary = self._summaries[project_id]
                report = self._run_impact(project_id, prd, summary)
                self._impacts[project_id] = report

                # Check for discoveries
                for dep in report.discovered_dependencies:
                    if dep not in self._repos and dep not in discovered:
                        discovered.add(dep)
                        if on_discovery and on_discovery(dep):
                            # User wants to add this repo
                            # Note: In real usage, they'd provide URL
                            # For now, just track it was discovered
                            pass

            discovery_round += 1
            if not discovered:
                break

        # Check context size before synthesis
        total_context_size = sum(len(report.raw_analysis) for report in self._impacts.values())
        if total_context_size > 500_000:  # 500KB warning threshold
            if on_progress:
                on_progress(
                    "synthesize",
                    f"Warning: Large context ({total_context_size:,} chars). "
                    "Consider reducing number of repos.",
                )

        # Phase 3: Synthesize
        if on_progress:
            on_progress("synthesize", "Generating HLD")

        hld = self._run_synthesize(prd, self._impacts)

        # Phase 4: Align
        if on_progress:
            on_progress("align", "Verifying alignment")

        alignment = self._run_align(prd, hld)

        # Handle alignment issues
        revision_round = 0
        while alignment.recommendation == "revise" and revision_round < self._max_revision_rounds:
            if on_alignment_issue:
                action = on_alignment_issue(alignment)
                if action == "accept":
                    break
                if action == "abort":
                    break
                # action == "revise" - continue loop
            else:
                break  # No callback, accept as-is

            revision_round += 1
            if on_progress:
                on_progress("synthesize", f"Revision round {revision_round}")

            hld = self._run_synthesize(prd, self._impacts)

            if on_progress:
                on_progress("align", "Re-verifying alignment")
            alignment = self._run_align(prd, hld)

        return hld, alignment
