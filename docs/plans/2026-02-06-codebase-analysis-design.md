# Codebase Analysis Feature Design

## Purpose

Add pre-computed codebase analysis to Shesha repositories. The analysis supplements the multi-repo HLD builder's reconnaissance phase, providing a "cheat sheet" that helps recon work faster while still validating by running the actual recon.

## Data Model

### Top-level structure

```json
{
  "version": "1",
  "generated_at": "2025-02-06T10:30:00Z",
  "head_sha": "abc123...",
  "overview": "High-level summary paragraph",
  "components": [...],
  "external_dependencies": [...],
  "caveats": "This analysis was generated by AI and may be incomplete or incorrect."
}
```

- `version` - Schema version for future evolution
- `generated_at` - Timestamp for informational purposes
- `head_sha` - Git SHA when analysis was generated (for staleness detection)
- `overview` - High-level summary paragraph
- `components` - Array of component objects
- `external_dependencies` - Services/APIs this codebase depends on
- `caveats` - Standard disclaimer about AI-generated content

### Component schema

```json
{
  "name": "Server API",
  "path": "server/",
  "description": "FastAPI service providing authenticated API for chat sessions...",
  "apis": [
    {
      "type": "rest",
      "endpoints": [
        "POST /api/chat/sessions/{session_id}/messages/stream",
        "POST /api/auth/token/refresh"
      ]
    }
  ],
  "models": ["ChatSession", "Message", "UserFeedback"],
  "entry_points": ["server/main.py"],
  "internal_dependencies": ["ai_layer"],
  "auth": "Validates AWS Cognito JWTs (RS256 with JWKS)",
  "data_persistence": "DynamoDB tables for session/chat-history/feedback"
}
```

- `name` - Human-readable component name
- `path` - Directory path within repo
- `description` - What this component does
- `apis` - Exposed APIs with type (rest/graphql/grpc/cli/events) and specifics
- `models` - Key data models/schemas this component defines
- `entry_points` - Main files/handlers
- `internal_dependencies` - Other components in same repo this depends on
- `auth` - How authentication works (optional)
- `data_persistence` - Storage mechanisms (optional)

### External dependencies schema

```json
{
  "name": "Amazon Bedrock",
  "type": "ai_service",
  "description": "Claude model for agent invocations",
  "used_by": ["ai_layer"],
  "optional": false
}
```

- `name` - Service/API name
- `type` - Category: external_api, database, message_queue, ai_service, auth_service, storage
- `description` - How it's used
- `used_by` - Which components use this dependency
- `optional` - Whether the system works without it (default false)

## Storage

Location: `{storage_path}/projects/{project_id}/_analysis.json`

Analysis is stored alongside project metadata and deleted when project is deleted.

## Python Data Models

Add to `src/shesha/models.py`:

```python
@dataclass
class AnalysisComponent:
    name: str
    path: str
    description: str
    apis: list[dict]  # [{type, endpoints/operations/commands}]
    models: list[str]
    entry_points: list[str]
    internal_dependencies: list[str]
    auth: str | None = None
    data_persistence: str | None = None

@dataclass
class AnalysisExternalDep:
    name: str
    type: str  # external_api, database, message_queue, ai_service, auth_service, storage
    description: str
    used_by: list[str]
    optional: bool = False

@dataclass
class RepoAnalysis:
    version: str
    generated_at: str
    head_sha: str
    overview: str
    components: list[AnalysisComponent]
    external_dependencies: list[AnalysisExternalDep]
    caveats: str = "This analysis was generated by AI and may be incomplete or incorrect."
```

## Shesha API

New methods on `Shesha` class:

- `get_analysis(project_id) -> RepoAnalysis | None` - Load existing analysis
- `generate_analysis(project_id) -> RepoAnalysis` - Generate new analysis via LLM
- `get_analysis_status(project_id) -> "current" | "stale" | "missing"` - Compare stored SHA vs current HEAD

The `ProjectInfo` dataclass gains an `analysis_status` field.

## Analysis Generation

New module: `src/shesha/analysis/`

```python
class AnalysisGenerator:
    def __init__(self, shesha: Shesha):
        self.shesha = shesha

    def generate(self, project_id: str) -> RepoAnalysis:
        project = self.shesha.get_project(project_id)
        result = project.query(ANALYSIS_PROMPT)
        analysis_data = extract_json(result.answer)
        head_sha = self._get_current_head_sha(project_id)

        return RepoAnalysis(
            version="1",
            generated_at=datetime.utcnow().isoformat(),
            head_sha=head_sha,
            **analysis_data
        )
```

Prompt stored in `src/shesha/analysis/prompts/generate.md`.

## Multi-Repo Analyzer Integration

Modify `src/shesha/experimental/multi_repo/analyzer.py`:

```python
def _run_recon(self, project_id: str) -> RepoSummary:
    project = self._shesha.get_project(project_id)
    analysis = self._shesha.get_analysis(project_id)

    if analysis:
        context = self._format_analysis_context(analysis)
        prompt = RECON_PROMPT_WITH_ANALYSIS.format(existing_analysis=context)
    else:
        prompt = RECON_PROMPT

    result = project.query(prompt)
    return self._parse_recon_result(result.answer)
```

New prompt: `src/shesha/experimental/multi_repo/prompts/recon_with_analysis.md`

The analysis acts as a "map" - recon still explores but knows where to look.

## repo.py CLI Changes

### On project load

After loading and checking for updates:

```python
analysis_status = shesha.get_analysis_status(project.project_id)

if analysis_status == "missing":
    print("Note: No codebase analysis exists for this repository.")
    response = input("Generate analysis? (y/n): ").strip().lower()
    if response == "y":
        print("Generating analysis (this may take a minute)...")
        shesha.generate_analysis(project.project_id)
        print("Analysis complete.")

elif analysis_status == "stale":
    print("Note: Codebase analysis is outdated (HEAD has moved).")
    response = input("Regenerate analysis? (y/n): ").strip().lower()
    if response == "y":
        print("Regenerating analysis...")
        shesha.generate_analysis(project.project_id)
        print("Analysis updated.")
```

### New interactive commands

- `analysis` or `show analysis` - Display the current analysis
- `analyze` or `regenerate analysis` - Force regenerate the analysis

### Updated help

```
Commands:
  help, ?              Show this help message
  analysis             Show codebase analysis
  analyze              Generate/regenerate codebase analysis
  write                Save session transcript
  write <filename>     Save session transcript to specified file
  quit, exit           Leave the session
```

## Analysis Display

Format JSON for terminal readability:

```python
def format_analysis_for_display(analysis: RepoAnalysis) -> str:
    lines = []
    lines.append(f"=== Codebase Analysis (generated {analysis.generated_at[:10]}) ===")
    lines.append(f"Git SHA: {analysis.head_sha[:8]}")
    lines.append("")
    lines.append("## Overview")
    lines.append(analysis.overview)
    lines.append("")
    lines.append("## Components")
    for comp in analysis.components:
        lines.append(f"\n### {comp.name} ({comp.path})")
        lines.append(comp.description)
        if comp.apis:
            lines.append(f"  APIs: {_format_apis(comp.apis)}")
        if comp.models:
            lines.append(f"  Models: {', '.join(comp.models)}")
        if comp.entry_points:
            lines.append(f"  Entry points: {', '.join(comp.entry_points)}")

    if analysis.external_dependencies:
        lines.append("\n## External Dependencies")
        for dep in analysis.external_dependencies:
            opt = " (optional)" if dep.optional else ""
            lines.append(f"  - {dep.name}{opt}: {dep.description}")

    lines.append(f"\n  {analysis.caveats}")
    return "\n".join(lines)
```

## Files to Create/Modify

### New files

- `src/shesha/analysis/__init__.py` - Module init, export public API
- `src/shesha/analysis/generator.py` - AnalysisGenerator class
- `src/shesha/analysis/prompts/generate.md` - Prompt for analysis generation
- `src/shesha/experimental/multi_repo/prompts/recon_with_analysis.md` - Modified recon prompt

### Modified files

- `src/shesha/models.py` - Add RepoAnalysis, AnalysisComponent, AnalysisExternalDep dataclasses
- `src/shesha/shesha.py` - Add get_analysis(), generate_analysis(), get_analysis_status() methods
- `src/shesha/storage/base.py` - Add store_analysis(), load_analysis() to protocol
- `src/shesha/storage/filesystem.py` - Implement analysis storage
- `src/shesha/experimental/multi_repo/analyzer.py` - Inject analysis context in recon
- `examples/repo.py` - Add analysis status alerts, `analysis` and `analyze` commands
- `examples/script_utils.py` - Add format_analysis_for_display(), is_analysis_command() helpers

### Test files

- `tests/analysis/test_generator.py`
- `tests/analysis/test_storage.py`
- `tests/experimental/test_multi_repo_with_analysis.py`
- `tests/examples/test_repo_analysis_commands.py`
